{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08a32e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9973f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5df34ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())  # Should print True if successful\n",
    "print(torch.cuda.device_count())  # Number of GPUs recognized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48de32eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_ad(ctr, impressions):\n",
    "    \"\"\"\n",
    "    Returns an integer label:\n",
    "      0 -> No success\n",
    "      1 -> Moderately viral\n",
    "      2 -> Very viral\n",
    "    \"\"\"\n",
    "    # Current rules\n",
    "    if impressions < 100_000 and ctr < 0.1:\n",
    "        return 0  # \"No success\"\n",
    "    elif impressions >= 300_000 or ctr >= 0.2:\n",
    "        return 2  # \"Very viral\"\n",
    "    else:\n",
    "        return 1  # \"Moderately viral\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12ce6815",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ViralAdsDataset(Dataset):\n",
    "    def __init__(self, image_folder, transform=None):\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "        self.image_paths = glob.glob(os.path.join(image_folder, \"*.jpg\"))\n",
    "        \n",
    "        # Regex to parse filenames like 0.12_100000_12.jpg\n",
    "        #   group(1) = CTR, group(2) = impressions, group(3) = id\n",
    "        self.pattern = re.compile(r\"^([\\d.]+)_([\\d]+)_(.+)\\.jpg$\")\n",
    "        \n",
    "        # Store (path, label) for each image\n",
    "        self.samples = []\n",
    "        for path in self.image_paths:\n",
    "            filename = os.path.basename(path)\n",
    "            match = self.pattern.match(filename)\n",
    "            if match:\n",
    "                ctr_str = match.group(1)\n",
    "                impressions_str = match.group(2)\n",
    "                # _id = match.group(3)  # if you need the ad id, you can parse it here\n",
    "                \n",
    "                try:\n",
    "                    ctr_value = float(ctr_str)\n",
    "                    impressions_value = float(impressions_str)\n",
    "                except:\n",
    "                    # skip if parse fails\n",
    "                    continue\n",
    "                \n",
    "                label = categorize_ad(ctr_value, impressions_value)\n",
    "                self.samples.append((path, label))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3ec2e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "dataset = ViralAdsDataset(image_folder=r\"C:\\Bakalauras\\filtered_images\", \n",
    "                          transform=img_transform)\n",
    "\n",
    "# Train-Test Split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ef23e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading pretrained ResNet (ResNet18)\n",
    "resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "num_ftrs = resnet.fc.in_features\n",
    "\n",
    "# Replace final layer with a 3-class classification layer\n",
    "resnet.fc = nn.Linear(num_ftrs, 3)\n",
    "\n",
    "model = resnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68ff66c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000         4\n",
      "           1     0.5455    0.1714    0.2609        35\n",
      "           2     0.7360    0.9485    0.8288        97\n",
      "\n",
      "    accuracy                         0.7206       136\n",
      "   macro avg     0.4272    0.3733    0.3632       136\n",
      "weighted avg     0.6653    0.7206    0.6583       136\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vadim\\.conda\\envs\\myenvTensor\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vadim\\.conda\\envs\\myenvTensor\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\vadim\\.conda\\envs\\myenvTensor\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# 1) Pretrained ResNet without final layer\n",
    "resnet_feature = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "resnet_feature.fc = nn.Identity()\n",
    "resnet_feature.eval()\n",
    "resnet_feature.to(device)\n",
    "\n",
    "# 2) Build embeddings dataset\n",
    "all_embeddings = []\n",
    "all_labels = []\n",
    "\n",
    "for images, labels in DataLoader(dataset, batch_size=16, shuffle=False):\n",
    "    images = images.to(device)\n",
    "    with torch.no_grad():\n",
    "        emb = resnet_feature(images)  # shape [batch_size, 512]\n",
    "    all_embeddings.append(emb.cpu().numpy())\n",
    "    all_labels.append(labels.numpy())\n",
    "\n",
    "all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "# 3) Train Test Split in sklearn style\n",
    "X_train, X_val, y_train, y_val = train_test_split(all_embeddings, all_labels, \n",
    "                                                  test_size=0.2, random_state=42)\n",
    "\n",
    "# 4) Random Forest\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# 5) Evaluate\n",
    "y_pred = rfc.predict(X_val)\n",
    "print(classification_report(y_val, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2d94363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.3088235294117647\n",
      "MSE: 0.36764705882352944\n",
      "RMSE: 0.6063390625908325\n",
      "R²: -0.3367\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# y_true and y_pred are arrays of shape [num_samples]\n",
    "# each entry is 0, 1, or 2 (the class)\n",
    "\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(f\"R²: {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
